{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install datasets tqdm pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mw3-vTOb1g9",
        "outputId": "b95c5f40-6d57-45c8-a6ba-6c3f5378407f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece transformers wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuObd2dEb-IG",
        "outputId": "0dc38138-05e6-4fa3-8bd1-a9517c1d99f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.39.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.42)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.43.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMhsVhy4b5Mt",
        "outputId": "d758b937-5cfa-4ce7-fd12-70962f074c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "df = pd.read_parquet(\"/content/drive/MyDrive/train-00000-of-00001.parquet\")\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PzIVMqKcBEC",
        "outputId": "b74930f5-5013-4be4-dbf9-143030f29416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(216318, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq\n",
        "  )\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "lGssnZF7cTZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 't5-base'\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuB0p4kacV71",
        "outputId": "a4e59b8a-7119-4e39-f236-d121241dbc90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_token_len(example):\n",
        "  return len(tokenizer(example).input_ids)"
      ],
      "metadata": {
        "id": "S9Mnxg_zcXOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df\n",
        "test_df = pd.read_parquet(\"/content/drive/MyDrive/test-00000-of-00001.parquet\")"
      ],
      "metadata": {
        "id": "tkAPJDtwcZT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "lsl1I8SicfJs",
        "outputId": "6298240c-98ea-4706-9731-3c867b738ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  lang  \\\n",
              "0   es   \n",
              "1   es   \n",
              "2   fr   \n",
              "3   de   \n",
              "4   de   \n",
              "\n",
              "                                                                                                                     sentence  \\\n",
              "0                                                                                    Ella tiene la opci√≥n de quedarse o irse.   \n",
              "1                                                                               Se puso colorada cuando le dijeron un piropo.   \n",
              "2                         La confrontation des t√©moins qui l'avaient rencontr√©e le jour de sa mort devait aider l'inspecteur.   \n",
              "3  Um bessere Aufkl√§rungsergebnisse zu bekommen, befahl General von Gronau einen begrenzten Angriff seines Korps nach Westen.   \n",
              "4                                                                                 Ich f√ºrchte, dass er mich nicht mehr liebt.   \n",
              "\n",
              "                                                                                                                                 modified  \\\n",
              "0                                                                                   fix grammar: Ella tiene lo opci√≥n de quedarse o irse.   \n",
              "1                                                                             fix grammar: Se puso colorada cuando le dijeron una piropo.   \n",
              "2                        fix grammar: L'confrontation des t√©moins qui le avaient rencontr√©e l'jour de sa mort devait aider le inspecteur.   \n",
              "3  fix grammar: Um bessere Aufkl√§rungsergebnisse zu bekommen, befahl General von Gronau der begrenzten Angriff seines Korpse nach Westen.   \n",
              "4                                                                                fix grammar: Ich furchte, dass er mich nicht mehr liebt.   \n",
              "\n",
              "                        transformation          sec_transformation  \\\n",
              "0  NounGenderAgreementChangerDestroyer                        None   \n",
              "1            GenderDeterminerDestroyer                        None   \n",
              "2           ApostropheChangerDestroyer                        None   \n",
              "3               DetNounNumberDestroyer  ArticleDefChangerDestroyer   \n",
              "4   DeRemoveSpecialCharactersDestroyer                        None   \n",
              "\n",
              "   __index_level_0__  \n",
              "0              54704  \n",
              "1              21839  \n",
              "2              11751  \n",
              "3               8787  \n",
              "4               9910  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2140f2f7-ec35-4bfd-93c5-d611fb454252\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lang</th>\n",
              "      <th>sentence</th>\n",
              "      <th>modified</th>\n",
              "      <th>transformation</th>\n",
              "      <th>sec_transformation</th>\n",
              "      <th>__index_level_0__</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>es</td>\n",
              "      <td>Ella tiene la opci√≥n de quedarse o irse.</td>\n",
              "      <td>fix grammar: Ella tiene lo opci√≥n de quedarse o irse.</td>\n",
              "      <td>NounGenderAgreementChangerDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>54704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>es</td>\n",
              "      <td>Se puso colorada cuando le dijeron un piropo.</td>\n",
              "      <td>fix grammar: Se puso colorada cuando le dijeron una piropo.</td>\n",
              "      <td>GenderDeterminerDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>21839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fr</td>\n",
              "      <td>La confrontation des t√©moins qui l'avaient rencontr√©e le jour de sa mort devait aider l'inspecteur.</td>\n",
              "      <td>fix grammar: L'confrontation des t√©moins qui le avaient rencontr√©e l'jour de sa mort devait aider le inspecteur.</td>\n",
              "      <td>ApostropheChangerDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>11751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>de</td>\n",
              "      <td>Um bessere Aufkl√§rungsergebnisse zu bekommen, befahl General von Gronau einen begrenzten Angriff seines Korps nach Westen.</td>\n",
              "      <td>fix grammar: Um bessere Aufkl√§rungsergebnisse zu bekommen, befahl General von Gronau der begrenzten Angriff seines Korpse nach Westen.</td>\n",
              "      <td>DetNounNumberDestroyer</td>\n",
              "      <td>ArticleDefChangerDestroyer</td>\n",
              "      <td>8787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>de</td>\n",
              "      <td>Ich f√ºrchte, dass er mich nicht mehr liebt.</td>\n",
              "      <td>fix grammar: Ich furchte, dass er mich nicht mehr liebt.</td>\n",
              "      <td>DeRemoveSpecialCharactersDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>9910</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2140f2f7-ec35-4bfd-93c5-d611fb454252')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2140f2f7-ec35-4bfd-93c5-d611fb454252 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2140f2f7-ec35-4bfd-93c5-d611fb454252');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99879373-517d-44af-b4a7-0091c16f748c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99879373-517d-44af-b4a7-0091c16f748c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99879373-517d-44af-b4a7-0091c16f748c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 2186,\n  \"fields\": [\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"fr\",\n          \"en\",\n          \"es\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2120,\n        \"samples\": [\n          \"La cream Legbar a \\u00e9t\\u00e9 normalis\\u00e9e en 1958 mais a presque disparu dans les ann\\u00e9es 1970 car les \\u0153ufs bleus n'\\u00e9taient pas appr\\u00e9ci\\u00e9s.\",\n          \"Il vaut mieux ne pas faire de trous dans le fond du pot permanent pour pouvoir le d\\u00e9terrer plus facilement apr\\u00e8s avoir sectionn\\u00e9 les racines du c\\u00f4t\\u00e9 avec une b\\u00eache.\",\n          \"You plan on joining the team, don't you?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modified\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2185,\n        \"samples\": [\n          \"fix grammar: D'un caract\\u00e8re parfois difficile, prompt en la col\\u00e8re comme en d\\u00e9couragement, Claude Monet est un grand travailleur qui n'h\\u00e9site pas en d\\u00e9fier les \\u00e9l\\u00e9ments pour pratiquer sa passion.\",\n          \"fix grammar: Owen Hart, Jim Neidhart y Davey Boy Smith subieron al ring y tuvieron unas conversaci\\u00f3n con Hart luego de conseguir tranquilizarlo.\",\n          \"fix grammar: Mike Ashley, Mammoth Book of British Kings and Queens (New York: Carroll & Graf, 1999), p. 279 For of Edwin's reign Oswald remained in Exile.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transformation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 54,\n        \"samples\": [\n          \"NounGenderChangerDestroyer\",\n          \"CommonMispellsDestroyer\",\n          \"DeterminersReplacer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sec_transformation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"GenderDeterminerDestroyer\",\n          \"DetNounNumberDestroyer\",\n          \"AdjectiveGenderChangeDestroyer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"__index_level_0__\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16294,\n        \"min\": 30,\n        \"max\": 57597,\n        \"num_unique_values\": 2150,\n        \"samples\": [\n          31192,\n          25820,\n          2698\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['input_token_len'] = test_df['modified'].apply(calc_token_len)"
      ],
      "metadata": {
        "id": "Wz1uzx21cad5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPIBpTGHdNCw",
        "outputId": "d18ef720-76c5-4e26-b39a-7d81423d6c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class GrammarDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer,print_text=False):\n",
        "        self.dataset = dataset\n",
        "        self.pad_to_max_length = False\n",
        "        self.tokenizer = tokenizer\n",
        "        self.print_text = print_text\n",
        "        self.max_len = 64\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "    def tokenize_data(self, example):\n",
        "        input_, target_ = example['modified'], example['sentence']\n",
        "\n",
        "        # tokenize inputs\n",
        "        tokenized_inputs = tokenizer(input_, pad_to_max_length=self.pad_to_max_length,\n",
        "                                            max_length=self.max_len,\n",
        "                                            return_attention_mask=True)\n",
        "\n",
        "        tokenized_targets = tokenizer(target_, pad_to_max_length=self.pad_to_max_length,\n",
        "                                            max_length=self.max_len,\n",
        "                                            return_attention_mask=True)\n",
        "\n",
        "        inputs={\"input_ids\": tokenized_inputs['input_ids'],\n",
        "            \"attention_mask\": tokenized_inputs['attention_mask'],\n",
        "            \"labels\": tokenized_targets['input_ids']\n",
        "        }\n",
        "\n",
        "        return inputs\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        inputs = self.tokenize_data(self.dataset[index])\n",
        "\n",
        "        if self.print_text:\n",
        "            for k in inputs.keys():\n",
        "                print(k, len(inputs[k]))\n",
        "\n",
        "        return inputs"
      ],
      "metadata": {
        "id": "QmsiZAoZdRmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = GrammarDataset(test_dataset, tokenizer, True)\n",
        "print(dataset[121])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E9xJQePdWUx",
        "outputId": "9bb26efa-2dcf-4c96-f4b9-1d6442526c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids 12\n",
            "attention_mask 12\n",
            "labels 10\n",
            "{'input_ids': [2210, 19519, 10, 3885, 6988, 20, 22089, 259, 4514, 9, 109, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1138, 6988, 20, 22089, 259, 4514, 9, 109, 5, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGvMOTqjdW2Y",
        "outputId": "b1f88a62-f0fd-4c98-d286-e1416a7e8341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "rouge_metric = load_metric(\"rouge\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obvxHAeKdiNi",
        "outputId": "e6b09d2a-c0a6-4284-824b-3575192b30a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-76fa4d2ef6b0>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge_metric = load_metric(\"rouge\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy-TWwrTiudO",
        "outputId": "40b75cf9-9020-4430-c9d2-546de475f58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest', return_tensors='pt')"
      ],
      "metadata": {
        "id": "1GaMpUGGdoWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1wTZaw-iv2n",
        "outputId": "6e061002-f246-43a1-d056-bb30d3f85acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.39.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[torch] -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxNHwe88jWG1",
        "outputId": "3961c393-4ca0-4898-d0ef-7103a68f01dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.39.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "args = Seq2SeqTrainingArguments(output_dir=\"/content/drive/MyDrive/multilingual-gec/weights\",\n",
        "                        evaluation_strategy=\"steps\",\n",
        "                        per_device_train_batch_size=batch_size,\n",
        "                        per_device_eval_batch_size=batch_size,\n",
        "                        learning_rate=2e-5,\n",
        "                        num_train_epochs=1,\n",
        "                        weight_decay=0.01,\n",
        "                        save_total_limit=2,\n",
        "                        predict_with_generate=True,\n",
        "                        fp16 = False,\n",
        "                        gradient_accumulation_steps = 6,\n",
        "                        eval_steps = 500,\n",
        "                        save_steps = 500,\n",
        "                        load_best_model_at_end=True,\n",
        "                        logging_dir=\"/logs\",\n",
        "                        report_to=\"wandb\")"
      ],
      "metadata": {
        "id": "gTRYeZp-dtyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZvYHioNd1Bh",
        "outputId": "2637a536-cbc8-443d-c899-436674861b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining trainer using ü§ó\n",
        "trainer = Seq2SeqTrainer(model=model,\n",
        "                args=args,\n",
        "                train_dataset= GrammarDataset(train_dataset, tokenizer),\n",
        "                eval_dataset=GrammarDataset(test_dataset, tokenizer),\n",
        "                tokenizer=tokenizer,\n",
        "                data_collator=data_collator,\n",
        "                compute_metrics=compute_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42PJbMEzd3Mg",
        "outputId": "2130af90-2bb1-4489-acf4-e428558ac0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('/content/drive/MyDrive/multilingual_gec')"
      ],
      "metadata": {
        "id": "CgztLP39z0eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.save_model('/content/drive/MyDrive/multilingual_gec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "CCcctvLdd3lC",
        "outputId": "213143d8-f829-4a7d-f71e-ca771059d44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='48' max='2253' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  48/2253 00:44 < 35:44, 1.03 it/s, Epoch 0.02/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d9dccd14a5ab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/multilingual_gec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1781\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2118\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3059\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3060\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3061\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1749\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1113\u001b[0m                 )\n\u001b[1;32m   1114\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1116\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0mquery_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             cross_attention_outputs = self.layer[1](\n\u001b[0m\u001b[1;32m    726\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[1;32m    634\u001b[0m     ):\n\u001b[1;32m    635\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         attention_output = self.EncDecAttention(\n\u001b[0m\u001b[1;32m    637\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# Mask heads if we want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlayer_head_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch_device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "l3DoHP6m1HT7",
        "outputId": "6f1f59fa-6581-45b2-f48e-e45350b7e1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "model_name = '/content/drive/MyDrive/multilingual-gec/weights/checkpoint-2000'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "def correct_grammar(input_text,num_return_sequences):\n",
        "  batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to(torch_device)\n",
        "  translated = model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
        "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "  return tgt_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePYjKOo9kn_W",
        "outputId": "57f05a0a-0b45-4ae8-f6e3-0f3df585ef80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_correct_text_recursively(model, tokenizer, input_text):\n",
        "    texts = correct_grammar(input_text, 4)\n",
        "    possible_text = {}\n",
        "    for text in texts:\n",
        "        temp = correct_grammar(text, 4)\n",
        "        temp.append(text)\n",
        "        for t in temp:\n",
        "            if t in possible_text.keys():\n",
        "                possible_text[t] +=1\n",
        "            else:\n",
        "                possible_text[t] = 1\n",
        "\n",
        "    return max(possible_text, key=possible_text.get)"
      ],
      "metadata": {
        "id": "vM8AOVWtnryr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_correct_text_recursively(model, tokenizer, \"fix grammar: I have good reason for avoiding Tom.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "UW60Xzxroka3",
        "outputId": "9890340d-1b6a-44c7-d62f-49bc42d5d511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I have good reason to avoid Tom.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_cases = pd.read_parquet(\"/content/drive/MyDrive/test-00000-of-00001.parquet\")\n",
        "test_cases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "tFJy6mSan_YQ",
        "outputId": "aeb76e71-b9e2-4a1a-ce35-d8d13547c436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     lang                                           sentence  \\\n",
              "0      es           Ella tiene la opci√≥n de quedarse o irse.   \n",
              "1      es      Se puso colorada cuando le dijeron un piropo.   \n",
              "2      fr  La confrontation des t√©moins qui l'avaient ren...   \n",
              "3      de  Um bessere Aufkl√§rungsergebnisse zu bekommen, ...   \n",
              "4      de        Ich f√ºrchte, dass er mich nicht mehr liebt.   \n",
              "...   ...                                                ...   \n",
              "2181   es  Se ha incrementado el servicio de transporte p...   \n",
              "2182   fr                   O√π avez-vous trouv√© ce couteau ?   \n",
              "2183   de  Am fr√ºhen Morgen des 27. Januar 1945 trafen de...   \n",
              "2184   es  Medio ambiente 2010: el futuro en nuestras manos.   \n",
              "2185   en   I have a fairly good idea what needs to be done.   \n",
              "\n",
              "                                               modified  \\\n",
              "0     fix grammar: Ella tiene lo opci√≥n de quedarse ...   \n",
              "1     fix grammar: Se puso colorada cuando le dijero...   \n",
              "2     fix grammar: L'confrontation des t√©moins qui l...   \n",
              "3     fix grammar: Um bessere Aufkl√§rungsergebnisse ...   \n",
              "4     fix grammar: Ich furchte, dass er mich nicht m...   \n",
              "...                                                 ...   \n",
              "2181  fix grammar: Se ha incrementado el servicio de...   \n",
              "2182      fix grammar: O√π as-vous trouvait ce couteau ?   \n",
              "2183  fix grammar: Am fr√ºhen Morgen des 27. Januar 1...   \n",
              "2184  fix grammar: Medio anbiente 2010: el futuro en...   \n",
              "2185  fix grammar: I have a fairly well idea what ne...   \n",
              "\n",
              "                           transformation          sec_transformation  \\\n",
              "0     NounGenderAgreementChangerDestroyer                        None   \n",
              "1               GenderDeterminerDestroyer                        None   \n",
              "2              ApostropheChangerDestroyer                        None   \n",
              "3                  DetNounNumberDestroyer  ArticleDefChangerDestroyer   \n",
              "4      DeRemoveSpecialCharactersDestroyer                        None   \n",
              "...                                   ...                         ...   \n",
              "2181               RemoveAccentsDestroyer                        None   \n",
              "2182               PersonVerbDisagreement         FrVerbNumberChanger   \n",
              "2183               DetNounNumberDestroyer                        None   \n",
              "2184               SimilarSoundsDestroyer                        None   \n",
              "2185               ReplaceTokensDestroyer                        None   \n",
              "\n",
              "      __index_level_0__  \n",
              "0                 54704  \n",
              "1                 21839  \n",
              "2                 11751  \n",
              "3                  8787  \n",
              "4                  9910  \n",
              "...                 ...  \n",
              "2181              14261  \n",
              "2182               2781  \n",
              "2183               4643  \n",
              "2184              29420  \n",
              "2185              22601  \n",
              "\n",
              "[2186 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13194183-3ed8-4155-9b3a-d70e45541988\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lang</th>\n",
              "      <th>sentence</th>\n",
              "      <th>modified</th>\n",
              "      <th>transformation</th>\n",
              "      <th>sec_transformation</th>\n",
              "      <th>__index_level_0__</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>es</td>\n",
              "      <td>Ella tiene la opci√≥n de quedarse o irse.</td>\n",
              "      <td>fix grammar: Ella tiene lo opci√≥n de quedarse ...</td>\n",
              "      <td>NounGenderAgreementChangerDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>54704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>es</td>\n",
              "      <td>Se puso colorada cuando le dijeron un piropo.</td>\n",
              "      <td>fix grammar: Se puso colorada cuando le dijero...</td>\n",
              "      <td>GenderDeterminerDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>21839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fr</td>\n",
              "      <td>La confrontation des t√©moins qui l'avaient ren...</td>\n",
              "      <td>fix grammar: L'confrontation des t√©moins qui l...</td>\n",
              "      <td>ApostropheChangerDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>11751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>de</td>\n",
              "      <td>Um bessere Aufkl√§rungsergebnisse zu bekommen, ...</td>\n",
              "      <td>fix grammar: Um bessere Aufkl√§rungsergebnisse ...</td>\n",
              "      <td>DetNounNumberDestroyer</td>\n",
              "      <td>ArticleDefChangerDestroyer</td>\n",
              "      <td>8787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>de</td>\n",
              "      <td>Ich f√ºrchte, dass er mich nicht mehr liebt.</td>\n",
              "      <td>fix grammar: Ich furchte, dass er mich nicht m...</td>\n",
              "      <td>DeRemoveSpecialCharactersDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>9910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181</th>\n",
              "      <td>es</td>\n",
              "      <td>Se ha incrementado el servicio de transporte p...</td>\n",
              "      <td>fix grammar: Se ha incrementado el servicio de...</td>\n",
              "      <td>RemoveAccentsDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>14261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2182</th>\n",
              "      <td>fr</td>\n",
              "      <td>O√π avez-vous trouv√© ce couteau ?</td>\n",
              "      <td>fix grammar: O√π as-vous trouvait ce couteau ?</td>\n",
              "      <td>PersonVerbDisagreement</td>\n",
              "      <td>FrVerbNumberChanger</td>\n",
              "      <td>2781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2183</th>\n",
              "      <td>de</td>\n",
              "      <td>Am fr√ºhen Morgen des 27. Januar 1945 trafen de...</td>\n",
              "      <td>fix grammar: Am fr√ºhen Morgen des 27. Januar 1...</td>\n",
              "      <td>DetNounNumberDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>4643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2184</th>\n",
              "      <td>es</td>\n",
              "      <td>Medio ambiente 2010: el futuro en nuestras manos.</td>\n",
              "      <td>fix grammar: Medio anbiente 2010: el futuro en...</td>\n",
              "      <td>SimilarSoundsDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>29420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2185</th>\n",
              "      <td>en</td>\n",
              "      <td>I have a fairly good idea what needs to be done.</td>\n",
              "      <td>fix grammar: I have a fairly well idea what ne...</td>\n",
              "      <td>ReplaceTokensDestroyer</td>\n",
              "      <td>None</td>\n",
              "      <td>22601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2186 rows √ó 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13194183-3ed8-4155-9b3a-d70e45541988')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13194183-3ed8-4155-9b3a-d70e45541988 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13194183-3ed8-4155-9b3a-d70e45541988');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5db20e21-c151-4ebb-a0b0-2b5d3fbdb981\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5db20e21-c151-4ebb-a0b0-2b5d3fbdb981')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5db20e21-c151-4ebb-a0b0-2b5d3fbdb981 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4766f105-aec2-4a19-a5c4-6bf7c2d9cb4a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_cases')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4766f105-aec2-4a19-a5c4-6bf7c2d9cb4a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_cases');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_cases",
              "summary": "{\n  \"name\": \"test_cases\",\n  \"rows\": 2186,\n  \"fields\": [\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"fr\",\n          \"en\",\n          \"es\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2120,\n        \"samples\": [\n          \"La cream Legbar a \\u00e9t\\u00e9 normalis\\u00e9e en 1958 mais a presque disparu dans les ann\\u00e9es 1970 car les \\u0153ufs bleus n'\\u00e9taient pas appr\\u00e9ci\\u00e9s.\",\n          \"Il vaut mieux ne pas faire de trous dans le fond du pot permanent pour pouvoir le d\\u00e9terrer plus facilement apr\\u00e8s avoir sectionn\\u00e9 les racines du c\\u00f4t\\u00e9 avec une b\\u00eache.\",\n          \"You plan on joining the team, don't you?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modified\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2185,\n        \"samples\": [\n          \"fix grammar: D'un caract\\u00e8re parfois difficile, prompt en la col\\u00e8re comme en d\\u00e9couragement, Claude Monet est un grand travailleur qui n'h\\u00e9site pas en d\\u00e9fier les \\u00e9l\\u00e9ments pour pratiquer sa passion.\",\n          \"fix grammar: Owen Hart, Jim Neidhart y Davey Boy Smith subieron al ring y tuvieron unas conversaci\\u00f3n con Hart luego de conseguir tranquilizarlo.\",\n          \"fix grammar: Mike Ashley, Mammoth Book of British Kings and Queens (New York: Carroll & Graf, 1999), p. 279 For of Edwin's reign Oswald remained in Exile.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transformation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 54,\n        \"samples\": [\n          \"NounGenderChangerDestroyer\",\n          \"CommonMispellsDestroyer\",\n          \"DeterminersReplacer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sec_transformation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"GenderDeterminerDestroyer\",\n          \"DetNounNumberDestroyer\",\n          \"AdjectiveGenderChangeDestroyer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"__index_level_0__\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16294,\n        \"min\": 30,\n        \"max\": 57597,\n        \"num_unique_values\": 2150,\n        \"samples\": [\n          31192,\n          25820,\n          2698\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_correct_text_recursively(model, tokenizer, \"Ellos estudio mucho para el examen\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6Rz-G2P2MBI",
        "outputId": "47b4204b-0f01-4f80-db1d-8c76909d8f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ellos estudio mucho para el examen.': 3,\n",
              " 'Ellos se estudio mucho para el examen.': 1,\n",
              " 'Ellos estudio mucha para el examen.': 1,\n",
              " 'Ellos sestudio mucho para el examen.': 1,\n",
              " 'Ellos estudio mucho para el examene.': 2,\n",
              " 'Ellos se estudio mucho para el examene.': 1,\n",
              " 'Ellos sestudio mucho para el examene.': 1,\n",
              " 'Ellos estudio mucho para el examen del ltimo.': 3,\n",
              " 'Ellos estudio mucho para el examen del lder.': 1,\n",
              " 'Ellos estudio mucho para el examen del lneo.': 1,\n",
              " 'Ellos estudio mucho para el examene del ltimo.': 3,\n",
              " 'Ellos estudio mucho para el examene del lder.': 1,\n",
              " 'Ellos estudio mucho para el examene del lneo.': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for test in test_cases.iloc:\n",
        "  res = get_correct_text_recursively(model, tokenizer, test[\"modified\"])\n",
        "  print(\"Input:\", test[\"modified\"])\n",
        "  print(\"Actual:\", test[\"sentence\"])\n",
        "  print(\"Predict:\", res)\n",
        "  print(\"------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKijT9221dop",
        "outputId": "cc96b13e-7a2c-489a-9948-a649e722227b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: fix grammar: Ella tiene lo opci√≥n de quedarse o irse.\n",
            "Actual: Ella tiene la opci√≥n de quedarse o irse.\n",
            "Predict: Ella tiene la oportunidad de quedarse o irse.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Se puso colorada cuando le dijeron una piropo.\n",
            "Actual: Se puso colorada cuando le dijeron un piropo.\n",
            "Predict: Se puso colorado cuando le dijeron un piropo.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: L'confrontation des t√©moins qui le avaient rencontr√©e l'jour de sa mort devait aider le inspecteur.\n",
            "Actual: La confrontation des t√©moins qui l'avaient rencontr√©e le jour de sa mort devait aider l'inspecteur.\n",
            "Predict: La confrontation des t√©moins qui le avaient rencontr√© le jour de sa mort devait aider le inspecteur.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Um bessere Aufkl√§rungsergebnisse zu bekommen, befahl General von Gronau der begrenzten Angriff seines Korpse nach Westen.\n",
            "Actual: Um bessere Aufkl√§rungsergebnisse zu bekommen, befahl General von Gronau einen begrenzten Angriff seines Korps nach Westen.\n",
            "Predict: Um bessere Aufkl√§rungsergebnisse zu bekommen, befahl General von Gronau den begrenzten Angriff seines Korps nach Westen.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ich furchte, dass er mich nicht mehr liebt.\n",
            "Actual: Ich f√ºrchte, dass er mich nicht mehr liebt.\n",
            "Predict: Ich furchte, dass er mich nicht mehr liebt.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Most of the recipients having been American.\n",
            "Actual: Most of the recipients have been American.\n",
            "Predict: Most of the recipients were American.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Dans les b√¢timent G, les fabrication augmente progressivement et les b√¢timent est agrandi au fur et √† mesure des besoins.\n",
            "Actual: Dans le b√¢timent G, la fabrication augmente progressivement et le b√¢timent est agrandi au fur et √† mesure des besoins.\n",
            "Predict: Dans le b√¢timent G, la fabrication augmente progressivement et le b√¢timent est agrandi au fur et √† mesure des besoins.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Er mag der lokaler Kunstler gewesen sein, der nur begrenzte Fahigkeiten hatte.\n",
            "Actual: Er mag ein lokaler K√ºnstler gewesen sein, der nur begrenzte F√§higkeiten hatte.\n",
            "Predict: Er mag der lokaler K√ºnstler gewesen sein, der nur begrenzte F√§higkeiten hatte.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: My favorite novelist am Tom Jackson.\n",
            "Actual: My favorite novelist is Tom Jackson.\n",
            "Predict: My favorite writer is Tom Jackson.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Actuellement, les directeur de Minnal FM est S. Kumaran.\n",
            "Actual: Actuellement, le directeur de Minnal FM est S. Kumaran.\n",
            "Predict: Actuellement, le directeur de Minnal FM est S. Kumaran.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: ; la realidad, sin embargo, es otra, ya que entre 1559 y 1624, epoca aurea de la novela pastoril, la continuacion de Gil Polo se imprimio siete veces, pero la de Alonso mas del doble, quince; fue, pues, un exito en su tiempo.\n",
            "Actual: ; la realidad, sin embargo, es otra, ya que entre 1559 y 1624, √©poca √°urea de la novela pastoril, la continuaci√≥n de Gil Polo se imprimi√≥ siete veces, pero la de Alonso m√°s del doble, quince; fue, pues, un √©xito en su tiempo.\n",
            "Predict: La realidad, sin embargo, es otra, ya que entre 1559 y 1624, epoca aurea de la novela pastoril, la continuaci√≥n de Gil Polo se imprimi√≥ siete veces,\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: En la conformacion de la Comision Directiva oficial es designado vocal y poco despues secretario de la agrupacion.\n",
            "Actual: En la conformaci√≥n de la Comisi√≥n Directiva oficial es designado vocal y poco despu√©s secretario de la agrupaci√≥n.\n",
            "Predict: En la conformaci√≥n de la Comisi√≥n Directiva oficial es designado vocal y poco despu√©s secretario de la agrupaci√≥n.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: J'ai d√ª prendre le premiere train, ce matin, afin d'arriver ici √† temps.\n",
            "Actual: J'ai d√ª prendre le premier train, ce matin, afin d'arriver ici √† temps.\n",
            "Predict: J'ai d√ª prendre le premier train, ce matin, afin d'arriver ici √† temps.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Il a cr√©√© l'projection unique r√©troazimutale conforme, qui porte d√©sormais sa nom : la projection de Littrow.\n",
            "Actual: Il a cr√©√© l'unique projection r√©troazimutale conforme, qui porte d√©sormais son nom : la projection de Littrow.\n",
            "Predict: Il a cr√©√© la projection unique r√©troazimutale conforme, qui porte aujourd'hui son nom : la projection de Littrow.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Der Mann ohne Geduld ist wie die Lampe ohne √ñl.\n",
            "Actual: Ein Mann ohne Geduld ist wie eine Lampe ohne √ñl.\n",
            "Predict: Der Mann ohne Geduld ist wie die Lampe ohne l.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Mac√≠as, 2009: 55 Despu√©s de esta victorias, lo quite√±os eran due√±os de Huancabamba, Chachapoyas y Huamachuco.\n",
            "Actual: Mac√≠as, 2009: 55 Despu√©s de estas victorias, los quite√±os eran due√±os de Huancabamba, Chachapoyas y Huamachuco.\n",
            "Predict: 55 Despu√©s de estas victorias, los quiteos eran dueos de Huancabamba, Chachapoyas y Huamachuco.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Hoy no he puesto unes pie fuera de las casa.\n",
            "Actual: Hoy no he puesto un pie fuera de la casa.\n",
            "Predict: Hoy no he puesto un pie fuera de la casa.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: A small child fell into a pit that weren't properly secured.\n",
            "Actual: A small child fell into a pit that wasn't properly secured.\n",
            "Predict: A small child fell into a pit that wasn't properly secured.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Pero todo cambiar√° para samanta cuando aparezca en su vida Gaspar (\n",
            "Actual: Pero todo cambiar√° para Samantha cuando aparezca en su vida Gaspar (\n",
            "Predict: Pero todo cambiar√° para semana cuando aparezca en su vida Gaspar (\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Este ha sido el mayor incendio ocurrida desde la creaci√≥n del parque en 1910.\n",
            "Actual: Este ha sido el mayor incendio ocurrido desde la creaci√≥n del parque en 1910.\n",
            "Predict: Este ha sido el maior incendio ocurrido desde la creaci√≥n del parque en 1910.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: L'a√©roport est cr√©√© en 1930 pour permettre au comt√© de Teton de disposer d'un a√©roport premier.\n",
            "Actual: L'a√©roport est cr√©√© en 1930 pour permettre au comt√© de Teton de disposer d'un premier a√©roport.\n",
            "Predict: L'a√©roport est cr√©√© en 1930 afin de permettre au comt√© de Teton de disposer d'un premier a√©roport.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Egemplo de eyo inclulle equipos de dice√±o de prollectos de alta tecnolog√≠a los cuales deben integrar opiniones de diferentes perzonas con diferentes √°reas de conosimiento.\n",
            "Actual: Ejemplo de ello incluye equipos de dise√±o de proyectos de alta tecnolog√≠a los cuales deben integrar opiniones de diferentes personas con diferentes √°reas de conocimiento.\n",
            "Predict: Egemplo de eyo inclulle equipos de diceo de prollectos de alta tecnologa los cuales deben integrar opiniones de diferentes perzonas con diferentes √°reas de\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Vous as ruinions ma vie.\n",
            "Actual: Vous avez ruin√© ma vie.\n",
            "Predict: Vous avez ruin√© ma vie.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Je suis rentr√© chez eux du fa√ßon subreptice.\n",
            "Actual: Je suis rentr√© chez eux de fa√ßon subreptice.\n",
            "Predict: Je suis rentr√© chez eux de mani√®re sous-reptice.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: En los 2001, los equipa obtuvo el tercer lugar en la Copa Cifa, y el segundo lugar en la Liga Mexicana Regional.\n",
            "Actual: En el 2001, el equipo obtuvo el tercer lugar en la Copa Cifa, y el segundo lugar en la Liga Mexicana Regional.\n",
            "Predict: En el 2001, la equipa obtuvo el tercer lugar en la Copa Cifa, y el segundo lugar en la Liga Mexicana Regional.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Cela peut produire naturellement en combinant des radicaux libres ou cela peut √™tre aid√© en ajoutant des stabilisants aux polym√®res.\n",
            "Actual: Cela peut se produire naturellement en combinant des radicaux libres ou cela peut √™tre aid√© en ajoutant des stabilisants aux polym√®res.\n",
            "Predict: Ceci peut produire naturellement en combinant des radicaux libres ou cela peut √™tre aid√© en ajoutant des stabilisants aux polym√®res.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: La maisons Hamad avant les fun√©raille.\n",
            "Actual: La maison Hamad avant les fun√©railles.\n",
            "Predict: La maison Hamad avant les fun√©railles.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Um seinen Rufe zu pointieren verkaufte Good bei den Konzerte T-Shirts mit dem Aufdrucke I Hear Matt Good Is a Real Asshole (Ich habe geh√∂rt, Matt Good ist ein richtiges Arschloch).\n",
            "Actual: Um seinen Ruf zu pointieren verkaufte Good bei den Konzerten T-Shirts mit dem Aufdruck I Hear Matt Good Is a Real Asshole (Ich habe geh√∂rt, Matt Good ist ein richtiges Arschloch).\n",
            "Predict: Um seinen Ruf zu pointieren verkaufte Good bei den Konzerten T-Shirts mit dem Aufdruck I Hear Matt Good Is a Real Asshole (Ich habe geh√∂rt, Matt Good ist ein richtiger Arschloch).\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ce est l'gar√ßon auquel j'pense.\n",
            "Actual: C'est le gar√ßon auquel je pense.\n",
            "Predict: C'est le gar√ßon auquel je pense.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: There having been proposals to mine in the area.\n",
            "Actual: There have been proposals to mine in the area.\n",
            "Predict: There are proposals to mine in the area.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: La hongrois ne connait pas les genres grammaticaux.\n",
            "Actual: Le hongrois ne connait pas les genres grammaticaux.\n",
            "Predict: La hongroise ne connait pas les genres grammaticaux.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: I knows nothing about Spain.\n",
            "Actual: I know nothing about Spain.\n",
            "Predict: I know nothing about Spain.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Hay algunos bellos ejemplas de estas ingenuas y graciosas obros en la antolog√≠o rom√°ntica Echos du temps pass√©, de Weckerlin.\n",
            "Actual: Hay algunos bellos ejemplos de estas ingenuas y graciosas obras en la antolog√≠a rom√°ntica Echos du temps pass√©, de Weckerlin.\n",
            "Predict: Hay algunos bellos ejemplos de estas ingenuas y graciosas obras en la antologa rom√°ntica Echos du pass√©, de Weckerlin.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: We dont live in Australia Were just visiting\n",
            "Actual: We don't live in Australia. We're just visiting.\n",
            "Predict: We don't live in Australia. We're just visiting.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Regie f√ºhrte Sebasti√°n Mu√±oz, der auch ein Drehb√ºche schrieb.\n",
            "Actual: Regie f√ºhrte Sebasti√°n Mu√±oz, der auch das Drehbuch schrieb.\n",
            "Predict: Die Regie f√ºhrte Sebasti√°n Muoz, der auch ein Drehbuch schrieb.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Jill Tracy Jacobs Biden nee Jacobs previously Stevenson born June 3 1951 citation  is an American educator\n",
            "Actual: Jill Tracy Jacobs Biden (nee Jacobs, previously Stevenson; born June 3, 1951 citation ) is an American educator.\n",
            "Predict: Jill Tracy Jacobs Biden nee Jacobs previously Stevenson (born June 3, 1951) is an American educator.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Eine gro√üe Anzahl an Zeichen, die in Unicode kodiert sind, macht es schwierig, Zeichenketten zu sortieren.\n",
            "Actual: Die gro√üe Anzahl an Zeichen, die in Unicode kodiert sind, macht es schwierig, Zeichenketten zu sortieren.\n",
            "Predict: Eine gro√üe Anzahl an Zeichen, die in Unicode kodiert sind, macht es schwierig, Zeichenketten zu sortieren.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: The men come back before nightfall.\n",
            "Actual: The men came back before nightfall.\n",
            "Predict: The men return before nightfall.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Unos auriculares y unos aud√≠fonos no son lo mismo a pesar que ambos sirvan para escuchar cosas.\n",
            "Actual: Unos auriculares y unos aud√≠fonos no son lo mismo a pesar de que ambos sirvan para escuchar cosas.\n",
            "Predict: Unos auriculares y unos audfonos no son lo mismo a pesar que ambos sirvan para escuchar cosas.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Me should tell you that my boss, Mr Tanaka, might try to take you drinking.\n",
            "Actual: I should tell you that my boss, Mr Tanaka, might try to take you drinking.\n",
            "Predict: I should tell you that my boss, Mr Tanaka, might try to take you drinking.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: El comandante de la canonera siniestrada, Elias Aguirre, fue enjuiciado.\n",
            "Actual: El comandante de la ca√±onera siniestrada, El√≠as Aguirre, fue enjuiciado.\n",
            "Predict: El comandante de la canci√≥n siniestrada, Elias Aguirre, fue enjuiciado.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Community service were usually done at little or no pay.\n",
            "Actual: Community service is usually done at little or no pay.\n",
            "Predict: Community service is usually done with little or no pay.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Il ne fut pas directement impliqu√© en les √©v√®nements de la Place du S√©nat.\n",
            "Actual: Il ne fut pas directement impliqu√© dans les √©v√®nements de la Place du S√©nat.\n",
            "Predict: Il n'a pas √©t√© directement impliqu√© dans les √©v√©nements de la Place du S√©nat.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Hence, Percy have a wide range of abilities.\n",
            "Actual: Hence, Percy has a wide range of abilities.\n",
            "Predict: Percy has a wide range of abilities.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Unter der Leitungen von Heinrich Arnold wurden etwa 20 Gesch√§ftsneugr√ºndungen (Spin-offs) durchgef√ºhrt.\n",
            "Actual: Unter der Leitung von Heinrich Arnold wurden etwa 20 Gesch√§ftsneugr√ºndungen (Spin-offs) durchgef√ºhrt.\n",
            "Predict: Unter der Leitung von Heinrich Arnold wurden etwa 20 Unternehmensneugr√ºndungen (Spin-Offs) durchgef√ºhrt.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: La agencia afirm√≥ que ellos respetamos el deseo de Nakta de realizar actividades en solitario en el g√©nero electr√≥nico, por lo que acordaron cancelar su contrato exclusivo.\n",
            "Actual: La agencia afirm√≥ que ellos respetan el deseo de Nakta de realizar actividades en solitario en el g√©nero electr√≥nico, por lo que acordaron cancelar su contrato exclusivo.\n",
            "Predict: La agencia afirm√≥ que ellos respetamos el deseo de Nakta de realizar actividades en solitario en el g√©nero electr√≥nico, por lo que acordaron a\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Centro de Arte Casa de Vacas, Parque de el Retiro de Madrid.\n",
            "Actual: Centro de Arte Casa de Vacas, Parque del Retiro de Madrid.\n",
            "Predict: Centro de Arte Casa de Vacas, Parque del Retiro de Madrid.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Am 24. kam es ebi Barfleur erneut zu einem Gefecht mit MTBs, bei dem MTB 671 versenkt wudre.\n",
            "Actual: Am 24. kam es bei Barfleur erneut zu einem Gefecht mit MTBs, bei dem MTB 671 versenkt wurde.\n",
            "Predict: Am 24. kam es wieder zu einem Gefecht mit MTBs, bei dem MTB 671 versenkt w√ºdre.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: D√®s que le r√©gime communiste perd de sa intransigeance id√©ologique, l‚Äôindustrie cin√©matographique prend de l‚Äôampleur.\n",
            "Actual: D√®s que le r√©gime communiste perd de son intransigeance id√©ologique, l‚Äôindustrie cin√©matographique prend de l‚Äôampleur.\n",
            "Predict: D√®s que le r√©gime communiste perd de son intransigeance id√©ologique, l‚Äôindustrie cin√©matographique prend de l‚Äôexemple.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Kenney s'arrange pour que sa voisine, Alice Steward Maxey, un autre infirmi√®re, s'occupe de l'enfant.\n",
            "Actual: Kenney s'arrange pour que sa voisine, Alice Steward Maxey, une autre infirmi√®re, s'occupe de l'enfant.\n",
            "Predict: Kenney s'arrange pour que sa voisine, Alice Steward Maxey, une autre infirmi√®re, s'occupe de l'enfant.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Sie liebt dich noch immer sehr\n",
            "Actual: Sie liebt dich noch immer sehr.\n",
            "Predict: Sie lieben dich noch immer sehr.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Estaba requerida su presencia para cualquier reuni√≥n cultural, que nunca rehus√≥ y en las que siempre sal√≠a airoso, muchas veces improvisando.\n",
            "Actual: Era requerida su presencia para cualquier reuni√≥n cultural, que nunca rehus√≥ y en las que siempre sal√≠a airoso, muchas veces improvisando.\n",
            "Predict: Estaba requerida su presencia para cualquier reuni√≥n cultural, que nunca rehus√≥ y en las que siempre sala airosa, muchas veces improvisando.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: I know Tom permit you to do that.\n",
            "Actual: I know Tom would permit you to do that.\n",
            "Predict: I know Tom will allow you to do that.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: tom me dijo que no se iba a atrasar, pero todavia no se aparece.\n",
            "Actual: Tom me dijo que no se iba a atrasar, pero todav√≠a no se aparece.\n",
            "Predict: Tom me dijo que no se iba a atrasar, pero todava no se aparece.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ils imaginions que le Soleil tournait autour de la Terre, la Terre √©tant immobile.\n",
            "Actual: Ils s'imaginaient que le Soleil tournait autour de la Terre, la Terre √©tant immobile.\n",
            "Predict: Ils imaginent que le Soleil tournait autour de la Terre, la Terre √©tant immobile.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Juntemonos para charlar.\n",
            "Actual: Junt√©monos para charlar.\n",
            "Predict: Juntem√≥nos para charlar.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: En esperanto no hay art√≠culo indefinido y solo unes art√≠culo definido.\n",
            "Actual: En esperanto no hay art√≠culo indefinido y solo un art√≠culo definido.\n",
            "Predict: En esp√©ranto no hay artculo indefinido y solo un artculo definido.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Vielleicht ist das ein eigentliche Problem.\n",
            "Actual: Vielleicht ist das das eigentliche Problem.\n",
            "Predict: Vielleicht ist das eigentliche Problem.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: I allow Tom to did what he wanted.\n",
            "Actual: I allowed Tom to do what he wanted.\n",
            "Predict: I let Tom do what he wanted.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: On l'a vu transformer sa peaux en acier organique, ou p√©trifier ses adversaire, ou encore voler dans les air, propuls√© par l'√©nergies.\n",
            "Actual: On l'a vu transformer sa peau en acier organique, ou p√©trifier ses adversaires, ou encore voler dans les airs, propuls√© par l'√©nergie.\n",
            "Predict: On l'a vu transformer ses peaux en acier organique, ou p√©trifier son adversaire, ou encore voler dans l'air, propuls√© par l'√©nergie.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Older coins normally cost more than newer ones but rarity matters moresome coins from the 1920s cost vast sums while some Roman coins cost very little\n",
            "Actual: Older coins normally cost more than newer ones, but rarity matters more-some coins from the 1920s cost vast sums, while some Roman coins cost very little.\n",
            "Predict: Older coins usually cost more than newer ones but rarity matters moresome coins from the 1920s cost vast sums while some Roman coins cost very little.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Es una de las figuros m√°s importantes de la literaturo moderna.\n",
            "Actual: Es una de las figuras m√°s importantes de la literatura moderna.\n",
            "Predict: Es una de las figuras m√°s importantes de la literatura moderna.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Sami essayais de vivre deux vies diff√©rentes.\n",
            "Actual: Sami essayait de vivre deux vies diff√©rentes.\n",
            "Predict: Sami essaya de vivre deux vies diff√©rentes.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: ¬øBebe cafe?\n",
            "Actual: ¬øBebe caf√©?\n",
            "Predict: Bebe Caf√©?\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: En ce cas, il s'agirait de quelque chose d'assez proche de ce qu'on appelle l'\n",
            "Actual: Dans ce cas, il s'agirait de quelque chose d'assez proche de ce qu'on appelle l'\n",
            "Predict: En ce cas, il s'agirait de quelque chose d'assez pr√®s de ce qu'on appelle l'\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ich kann eine Adresse meines Hotels nicht finden.\n",
            "Actual: Ich kann die Adresse meines Hotels nicht finden.\n",
            "Predict: Ich kann die Adresse meines Hotels nicht finden.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: De plus, il subit une perte personnelle d√©vastatrice avec la mort de sa fils unique, William A. Buford, √† l'√¢ge de 23 ans en 1872.\n",
            "Actual: De plus, il subit une perte personnelle d√©vastatrice avec la mort de son fils unique, William A. Buford, √† l'√¢ge de 23 ans en 1872.\n",
            "Predict: De plus, il subit une perte personnelle d√©vastatrice avec la mort de son fils unique, William A. Buford, √† l'√¢ge de 23 ans en 1872.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: No es f√°cil aprender esta t√©cnico.\n",
            "Actual: No es f√°cil aprender esta t√©cnica.\n",
            "Predict: No es f√°cil aprender esta t√©cnica.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Me asom√© a la muerte y Paloma de la paz son dos colecciones que ti√±eron de rojo la relaci√≥n de la autora con el binomio vidamuerte\n",
            "Actual: Me asom√© a la muerte y Paloma de la paz son dos colecciones que ti√±eron de rojo la relaci√≥n de la autora con el binomio vida-muerte.\n",
            "Predict: Me asom√© a la muerte y Paloma de la paz son dos colecciones que tieron de rojo la relaci√≥n de la autora con el binomio vidamuerzo.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Du jardin organis√© par Marguerite de Flandre et de la roseraie vaste qui en √©tait le ornement principal il ne reste plus rien aujourd‚Äôhui.\n",
            "Actual: Du jardin organis√© par Marguerite de Flandre et de la vaste roseraie qui en √©tait le principal ornement il ne reste plus rien aujourd‚Äôhui.\n",
            "Predict: Du jardin organis√© par Marguerite de Flandre et de la vaste roseraie qui en √©tait le principal ornement il ne reste plus rien aujourd‚Äôhui.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Jills Tracys Jacobss Bidens (nees Jacobss, previously Stevensons; born Junes 3, 1951 citations ) is an American educators.\n",
            "Actual: Jill Tracy Jacobs Biden (nee Jacobs, previously Stevenson; born June 3, 1951 citation ) is an American educator.\n",
            "Predict: Jill Tracy Jacobs Bidens (nee Jacobs, previously Stevenson; born June 3, 1951 citations ) is an American educator.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: In der Saison 1949/50 veranstaltete der DFB den Landerpokal, wobei in jener Saison zum ersten und letzten Mal Vertragsspieler spielberechtigt waren und auch die ostdeutschen Landervertretungen teilnahmen, nicht jedoch das Saarland.\n",
            "Actual: In der Saison 1949/50 veranstaltete der DFB den L√§nderpokal, wobei in jener Saison zum ersten und letzten Mal Vertragsspieler spielberechtigt waren und auch die ostdeutschen L√§ndervertretungen teilnahmen, nicht jedoch das Saarland.\n",
            "Predict: In der Saison 1949/50 veranstaltete die DFB das Landerpokal, wobei in jener Saison zum ersten und letzten Mal Vertragsspieler spielberechtigt waren und auch die ostdeutschen Landervertretungen teilnahmen, nicht jedoch das Saarland.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Este extremo sur estaba 2 m por debajo de el nivel de la adyacente Stoa de Zeus.\n",
            "Actual: Este extremo sur estaba 2 m por debajo del nivel de la adyacente Stoa de Zeus.\n",
            "Predict: Este extremo sur se estaba 2 m por debajo del nivel de la adyacente Stoa de Zeus.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Los √°lbum incluye la canciones ¬´Derroche de amor¬ª, adem√°s de temos como ¬´Te respiro¬ª, ¬´Mi fiesta¬ª y ¬´Reflejo de ti¬ª, esta √∫ltima fue compuesta por Misael Villalobos, ganador del concursa que organiz√≥ Alex Campos a trav√©s de las redes sociales.\n",
            "Actual: El √°lbum incluye las canciones ¬´Derroche de amor¬ª, adem√°s de temas como ¬´Te respiro¬ª, ¬´Mi fiesta¬ª y ¬´Reflejo de ti¬ª, esta √∫ltima fue compuesta por Misael Villalobos, ganador del concurso que organiz√≥ Alex Campos a trav√©s de las redes sociales.\n",
            "Predict: El √°lbum incluye las canciones ¬´Derroche de amor¬ª, adem√°s de temos como ¬´Te respiro¬ª, ¬´Mi fiesta¬ª y ¬´Reflejo de ti¬ª, esta el\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: He played 9 games for Japan until 2019\n",
            "Actual: He played 9 games for Japan until 2019.\n",
            "Predict: He played 9 games for Japan until 2019.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: l√â es maestro cno experiencia.\n",
            "Actual: √âl es maestro con experiencia.\n",
            "Predict: L√â es maestro cno experiencia.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Il a remis sa d√©mission √† son parton.\n",
            "Actual: Il a remis sa d√©mission √† son patron.\n",
            "Predict: Il a remis sa d√©mission √† son parti.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: That other drug am called L-dopa.\n",
            "Actual: That other drug is called L-dopa.\n",
            "Predict: That other drug is called L-Dopa.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Cette bandes de fr√©quence est d√©di√©e au LTE et au LTE advanced (\n",
            "Actual: Cette bande de fr√©quence est d√©di√©e au LTE et au LTE advanced (\n",
            "Predict: Cette bande de fr√©quence est d√©di√©e au LTE et au LTE advanced (\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: On aurait d'ailleurs la impossibilit√© m√™me avec une impersonnelle forme comme ¬´ la chaleur qu'il s'est fait.\n",
            "Actual: On aurait d'ailleurs la m√™me impossibilit√© avec une forme impersonnelle comme ¬´ la chaleur qu'il s'est fait.\n",
            "Predict: On aurait d'ailleurs la possibilit√© m√™me avec une forme impersonnelle comme ¬´ la chaleur qu'il s'est fait.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: ¬øDe qu√© est√° hecha lo aspirina?\n",
            "Actual: ¬øDe qu√© est√° hecha la aspirina?\n",
            "Predict: De qu√© est√° hecha el aspirino?\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: La sp√©cificit√©s des modalit√©s de diagnostic a fait l‚Äôobjets de plusieurs √©tude d‚Äô√©valuation d‚Äôefficacit√©.\n",
            "Actual: La sp√©cificit√© des modalit√©s de diagnostic a fait l‚Äôobjet de plusieurs √©tudes d‚Äô√©valuation d‚Äôefficacit√©.\n",
            "Predict: La sp√©cificit√© des modalit√©s de diagnostic a fait l‚Äôobjet de plusieurs √©tudes d‚Äô√©valuation d‚Äôefficacit√©.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Il a r√©ussi √† attraper l'gros rat dans l'cuisine.\n",
            "Actual: Il a r√©ussi √† attraper le gros rat dans la cuisine.\n",
            "Predict: Il a r√©ussi √† attraper le gros rat dans la cuisine.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: esto t√©cnica, utilizada para m√°quinas de vector convencional, intenta encontrar y explotar SIMD paralelismo en el nivel de bucle.\n",
            "Actual: Esta t√©cnica, utilizada para m√°quinas de vector convencional, intenta encontrar y explotar SIMD paralelismo en el nivel de bucle.\n",
            "Predict: Esta t√©cnica, utilizada para m√°quinas de vector convencional, intenta encontrar y explotar SIMD paralelismo en el nivel de bucle.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Avez quelque chose a manger ?\n",
            "Actual: Avez-vous quelque chose √† manger ?\n",
            "Predict: Avez-vous quelque chose √† manger?\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: La musique est l'ame de la geometrie.\n",
            "Actual: La musique est l'√¢me de la g√©om√©trie.\n",
            "Predict: La musique est l'√¢me de la geom√©trie.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: En 1989 se organiz√≥ la primera exposici√≥n canina de Chodsk√Ω Pes en Doma≈ælice, y se han registrado alrededor de 3.500 nacimientas de cachorras desde que el programo comenz√≥ (1984-2009).\n",
            "Actual: En 1989 se organiz√≥ la primera exposici√≥n canina de Chodsk√Ω Pes en Doma≈ælice, y se han registrado alrededor de 3.500 nacimientos de cachorros desde que el programa comenz√≥ (1984-2009).\n",
            "Predict: En 1989 se organiz√≥ la primera exposici√≥n canina de Chodsk Pes en Domalice, y se han registrado alrededor de 3.500 nacimientos de cachorra.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: I telephoned my friend for congratulate him.\n",
            "Actual: I telephoned my friend to congratulate him.\n",
            "Predict: I telephoned my friend to congratulate him.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: The game was drawn\n",
            "Actual: The game was drawn.\n",
            "Predict: The game was drawn.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ninguno de los acusados fue encontrado culpable\n",
            "Actual: Ninguno de los acusados fue encontrado culpable.\n",
            "Predict: Ningn de los acusados fue encontrado culpable.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: L'acier travaille quand il fait chaud, la Tour Eiffel gagne plusieurs centim√®tres √† √©t√©.\n",
            "Actual: L'acier travaille quand il fait chaud, la Tour Eiffel gagne plusieurs centim√®tres en √©t√©.\n",
            "Predict: L'acier travaille quand il fait chaud, le Tour Eiffel gagne plusieurs centim√®tres √† √™tre.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Me was patting my dog.\n",
            "Actual: I was patting my dog.\n",
            "Predict: I was patting my dog.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: El ex fiscal de distrita, Iv√°n Lezama, fue quien llev√≥ los caso.\n",
            "Actual: El ex fiscal de distrito, Iv√°n Lezama, fue quien llev√≥ el caso.\n",
            "Predict: El ex fiscal de distrita, Iv√°n Lezama, fue quien llev√≥ el caso.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Interviews with Sugar feature on Unforgivable Blackness: The Rise and Fall of Jack Johnson.\n",
            "Actual: Interviews with Sugar feature in Unforgivable Blackness: The Rise and Fall of Jack Johnson.\n",
            "Predict: Interview with Sugar features on Unforgivable Blackness: The Rise and Fall of Jack Johnson.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Die Musik des St√ºckese ist im Stil der 60er-jahr gehalten.\n",
            "Actual: Die Musik des St√ºckes ist im Stil der 60er-Jahre gehalten.\n",
            "Predict: Die Musik des St√ºckes ist im Stil des 60er-Jahres gehalten.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Evaluaci√≥n de el funci√≥n plaquetaria con agregometr√≠a.\n",
            "Actual: Evaluaci√≥n de la funci√≥n plaquetaria con agregometr√≠a.\n",
            "Predict: Evaluaci√≥n de la funci√≥n plaquetara con agregometra.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Varios grupos farmacol√≥gicas han demostrado eficacia y se consideran como de elecci√≥n en la MW: agentes alquilantes (clorambucil y ciclofosfamida), an√°logos de las purinas (fludarabina y 2-CdA) y anti-CD20.\n",
            "Actual: Varios grupos farmacol√≥gicos han demostrado eficacia y se consideran como de elecci√≥n en la MW: agentes alquilantes (clorambucil y ciclofosfamida), an√°logos de las purinas (fludarabina y 2-CdA) y anti-CD20.\n",
            "Predict: Varios grupos farmacol√≥gicos han demostrado eficacia y se consideran como de elecci√≥n en la MW: agentes alquilantes (clorambucil y ciclofol).\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: tom told everyone that he were glad that were going to happen.\n",
            "Actual: Tom told everyone that he was glad that was going to happen.\n",
            "Predict: Tom told everyone that he was glad that was going to happen.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Kinn, Kehle und obere Brust sind gl√§nzend smaragdgr√ºn, w√§hrend sich eine Unterseite von eine unteren Brust ab, √ºber eine G√ºrtelpartie und ein Bauch purpurfarben darstellen und im weiteren Verlauf eine zum Stei√ü hin grau.\n",
            "Actual: Kinn, Kehle und obere Brust sind gl√§nzend smaragdgr√ºn, w√§hrend sich die Unterseite von der unteren Brust ab, √ºber die G√ºrtelpartie und den Bauch purpurfarben darstellen und im weiteren Verlauf die zum Stei√ü hin grau.\n",
            "Predict: Kinn, Kehle und obere Brust sind gl√§nzend smaragdgr√ºn, w√§hrend sich die Unterseite von der unteren Brust ab, √ºber die G√ºrtelpartie und das Bauch purpurfarben darstellen und im weiteren Verlauf eine zum St√ºtzpunkt\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Si le soleil s'arretait de briller, tous les etres vivants mourraient.\n",
            "Actual: Si le soleil s'arr√™tait de briller, tous les √™tres vivants mourraient.\n",
            "Predict: Si le soleil s'arr√©tait de briller, tous les √©tres vivants mourraient.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Bitte bring das Band morgen zuruck.\n",
            "Actual: Bitte bring das Band morgen zur√ºck.\n",
            "Predict: Bitte bring das Band morgen zur√ºck.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Je devient certainement fou.\n",
            "Actual: Je deviens certainement fou.\n",
            "Predict: Je me deviens certainement fou.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Il a choisi le nom du la berg√®re Amaryllis (de le grec \"amarusso\", qui signifie : \"Je p√©tille\"), chant√©e par Virgile dans ses \"Bucoliques, bien que ce nom ait d√©j√† √©t√© attribu√© √† une plante sud-africaine (amaryllis belladonna).\n",
            "Actual: Il a choisi le nom de la berg√®re Amaryllis (du grec \"amarusso\", qui signifie : \"Je p√©tille\"), chant√©e par Virgile dans ses \"Bucoliques, bien que ce nom ait d√©j√† √©t√© attribu√© √† une plante sud-africaine (amaryllis belladonna).\n",
            "Predict: Il a choisi le nom de la berg√®re Amaryllis (de la grecque \"amarusso\", qui signifie : \"Je p√©tille\"), chant√©e par Virgile dans ses \"Bucoliques, bien que ce nom ait √©t√©\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: In 1911, Internationals Womens's Days was celebrated for the first times in Austrias, Denmarks, Germanys and Switzerlands.\n",
            "Actual: In 1911, International Women's Day was celebrated for the first time in Austria, Denmark, Germany and Switzerland.\n",
            "Predict: In 1911, International Women's Day was celebrated for the first time in Austria, Denmark, Germany and Switzerland.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Probablemente hubo unes hom√≥nimo que se dedic√≥ a la mismas profesi√≥n.\n",
            "Actual: Probablemente hubo un hom√≥nimo que se dedic√≥ a la misma profesi√≥n.\n",
            "Predict: Probablemente hubo un hom√≥nimo que se dedica a la misma profesi√≥n.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Shane Ward lo marc√≥ como una acto de apoyo para la concierto, en que Kian lo describi√≥ como una \"espect√°culo de pop\".\n",
            "Actual: Shane Ward lo marc√≥ como un acto de apoyo para el concierto, en que Kian lo describi√≥ como un \"espect√°culo de pop\".\n",
            "Predict: Shane Ward lo marc√≥ como un acto deapoyo para el concierto, en que Kian lo describi√≥ como un \"espect√°culo de pop\".\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Tom want the same thing Mary wants.\n",
            "Actual: Tom wants the same thing Mary wants.\n",
            "Predict: Tom wants the same thing Mary wants.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: El Concejo de Educasi√≥n homenage√≥ al alcalde LaGuardia de manera p√≥stuma en el nonbre del nuevo edifisio.\n",
            "Actual: El Consejo de Educaci√≥n homenaje√≥ al alcalde LaGuardia de manera p√≥stuma en el nombre del nuevo edificio.\n",
            "Predict: El Concejo de Educaci√≥n homenage√≥ al alcalde LaGuardia de manera p√≥stuma en el nuevo edifisio.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Cette ville, situ√©e sur un plateau haute √† de la fronti√®re de l‚ÄôAfrique de l‚ÄôEst (actuel Kenya), √©tait √† la fois un port et le point de d√©part de la ferr√©e voie d strat√©gique‚Äô\n",
            "Actual: Cette ville, situ√©e sur un haut plateau √† de la fronti√®re de l‚ÄôAfrique de l‚ÄôEst (actuel Kenya), √©tait √† la fois un port et le point de d√©part de la voie ferr√©e strat√©gique d‚Äô\n",
            "Predict: Cette ville, situ√©e sur un haut plateau √† la fronti√®re de l‚ÄôAfrique de l‚ÄôEst (actuel Kenya), √©tait √† la fois un port et le point de d√©part de la voie ferr√©e d‚Äôint√©r√™t strat√©gique.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: J'a une femme et un enfant.\n",
            "Actual: J'ai une femme et un enfant.\n",
            "Predict: Je viens d'une femme et d'un enfant.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Estos √∫ltimos zon hijos de su actual espoza Deborah.\n",
            "Actual: Estos √∫ltimos son hijos de su actual esposa Deborah.\n",
            "Predict: Estos ltimos son hijos de su actual espaol Deborah.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Jen avons pris soin\n",
            "Actual: J'en ai pris soin.\n",
            "Predict: Jen a pris soin.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ces deux √©v√©nements derniers se sont produits √† Burnt River, en Ontario.\n",
            "Actual: Ces deux derniers √©v√©nements se sont produits √† Burnt River, en Ontario.\n",
            "Predict: Ces deux derniers √©v√©nements se sont produits √† Burnt River, en Ontario.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Los desaf√≠os diarios volv√≠a pero ahora con tres variantes, desaf√≠o diario, desaf√≠o avanzado y desaf√≠o de comunidad.\n",
            "Actual: Los desaf√≠os diarios vuelven pero ahora con tres variantes, desaf√≠o diario, desaf√≠o avanzado y desaf√≠o de comunidad.\n",
            "Predict: Los desafos diario volvan pero ahora con tres variantes, desafo diario, desafo avanzado y desafo de comunidad.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Dan's body were floating in the swimming pool.\n",
            "Actual: Dan's body was floating in the swimming pool.\n",
            "Predict: Dan's body was floating in the pool.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: where we sit?\n",
            "Actual: Where shall we sit?\n",
            "Predict: Where do we sit?\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: El 19 de junio de 2017, Blackstone adquiri√≥ una partisipasi√≥n malloritaria en The Offise Group, valorando la empreza en 640 miyones de d√≥lares.\n",
            "Actual: El 19 de junio de 2017, Blackstone adquiri√≥ una participaci√≥n mayoritaria en The Office Group, valorando la empresa en 640 millones de d√≥lares.\n",
            "Predict: El 19 de junio de 2017, Blackstone adquiri√≥ una partisi√≥n malloritaria en The Offise Group, valorando la empresa en 640 miyones de d√≥lares.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: I wish the doctors could finding out what's wrong with me.\n",
            "Actual: I wish the doctors could find out what's wrong with me.\n",
            "Predict: I wish the doctors could find out what's wrong with me.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ein Strom, der ein Feuer weiter nahrte, lieb sich nicht abstellen.\n",
            "Actual: Der Strom, der das Feuer weiter n√§hrte, lie√ü sich nicht abstellen.\n",
            "Predict: Der Strom, der das Feuer weiter nahte, liebt sich nicht abstellen.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: You shall having an answer tomorrow.\n",
            "Actual: You shall have an answer tomorrow.\n",
            "Predict: You'll have an answer tomorrow.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Das gangigste niederlandische Schimpfwort kut (als Unmutsbezeugung, etwa ‚ÄûMist!‚Äú) verweist auf das weibliche Genital.\n",
            "Actual: Das g√§ngigste niederl√§ndische Schimpfwort kut (als Unmutsbezeugung, etwa ‚ÄûMist!‚Äú) verweist auf das weibliche Genital.\n",
            "Predict: Das gr√∂√üte niederl√§ndische Schimpfwort kut (als Unmutsbezeugung, etwa ‚ÄûMist!‚Äú) verweist auf das weibliche Genital.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Son fa√ßon de penser est banale\n",
            "Actual: Sa fa√ßon de penser est banale.\n",
            "Predict: Sa fa√ßon de penser est banale.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Finalmente, John Vernon fue elegir√© como Wormer despu√©s de que Landis lo ver√° en The Outlaw Josey Wales.\n",
            "Actual: Finalmente, John Vernon fue elegido como Wormer despu√©s de que Landis lo viera en The Outlaw Josey Wales.\n",
            "Predict: Finalmente, John Vernon fue elegir√© como Wormer despu√©s de que Landis lo ver√° en The Outlaw, Josey Wales.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: There are a variety different flavours of Turkish delights for example rise water, lemon and chocolate.\n",
            "Actual: There are a variety different flavours of Turkish delights for example rose water, lemon and chocolate.\n",
            "Predict: There are a variety of different flavours of Turkish delights, for example rise water, lemon and chocolate.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Se daba en rejiones anbientalmente aptas para daba sustento a su poblasi√≥n pero donde sus habitantes sufr√≠a hanbre (en cazos extremos, ce produc√≠a los alimentos nesezarios, pero la poblasi√≥n ce ve√≠a privada de utilisarlaba).\n",
            "Actual: Se da en regiones ambientalmente aptas para dar sustento a su poblaci√≥n pero donde sus habitantes sufren hambre (en casos extremos, se producen los alimentos necesarios, pero la poblaci√≥n se ve privada de utilizarlos).\n",
            "Predict: Se daba en rejiones anbientalmente aptas para daba sustento a su poblaci√≥n pero donde sus habitantes sufra hanbre (en casos extremos).\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: La acumulaci√≥n de polvo en los ventiladores del ordenador fue la causa que se averiase.\n",
            "Actual: La acumulaci√≥n de polvo en los ventiladores del ordenador fue la causa de que se averiase.\n",
            "Predict: La acumulaci√≥n de polvo en los ventiladores del ordenador fue la causa que se averase.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Dabei fiel er mehrfach auf.\n",
            "Actual: Dabei fiel er mehrfach polizeilich auf.\n",
            "Predict: Dabei ist er mehrfach auf.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Je ai √©t√© surprise.\n",
            "Actual: J'ai √©t√© surprise.\n",
            "Predict: J'ai √©t√© surprise.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: El hebreo es un idioma dif√≠sil.\n",
            "Actual: El hebreo es un idioma dif√≠cil.\n",
            "Predict: El hebreo es un idioma difcil.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Le plus grand d√©p√¥t de ce types, situ√© √† Milford, fut ras√© en 1979.\n",
            "Actual: Le plus grand d√©p√¥t de ce type, situ√© √† Milford, fut ras√© en 1979.\n",
            "Predict: Le plus grand d√©p√¥t de ce type, situ√© √† Milford, fut r√©s√© en 1979.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: We were given something to eating.\n",
            "Actual: We were given something to eat.\n",
            "Predict: We were given something to eat.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Elle se r√©veille en m√™me temps que lui\n",
            "Actual: Elle se r√©veille en m√™me temps que lui.\n",
            "Predict: Elle se r√©veille au m√™me temps que lui.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: les matelots r√©fl√©chissent √† la sauce et √† la mani√®re du le pr√©parer (fricass√©, frit).\n",
            "Actual: Les matelots r√©fl√©chissent √† la sauce et √† la mani√®re de le pr√©parer (fricass√©, frit).\n",
            "Predict: Les matelots r√©fl√©chissent √† la sauce et √† la fa√ßon de la pr√©parer (fricass√©, frit).\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Die Grundfarben variiert von fast Wei√ü √ºber unterschiedliche Braunt√∂ne bis zu Wein- oder Violettrot.\n",
            "Actual: Die Grundfarbe variiert von fast Wei√ü √ºber unterschiedliche Braunt√∂ne bis zu Wein- oder Violettrot.\n",
            "Predict: Die Grundfarben variieren von fast Wei√ü √ºber unterschiedliche Braunt√∂ne bis hin zu Wein- oder Violettrot.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Le Rida passent en-dessous au moyen d‚Äôun pertuis qui d√©bouchent au pied de l‚Äôancienne d√©charge.\n",
            "Actual: Le Rida passe en-dessous au moyen d‚Äôun pertuis qui d√©bouche au pied de l‚Äôancienne d√©charge.\n",
            "Predict: Le Rida passe en-dessous au moyen d‚Äôun pertuis qui d√©bouchent au pied de l‚Äôancienne d√©charge.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Mientras Kingsley ce inbolucra con Urich, Max Modell alluda a Peter a escapar.\n",
            "Actual: Mientras Kingsley se involucra con Urich, Max Modell ayuda a Peter a escapar.\n",
            "Predict: Mientras Kingsley se inbolucra con Urich, Max Modell allud√≥ a Peter a escapar.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: I know I have to do sometime week.\n",
            "Actual: I know I have to do that sometime this week.\n",
            "Predict: I know I have to do that sometime this week.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Your patient, aren't you?\n",
            "Actual: You're patient, aren't you?\n",
            "Predict: You're a patient, aren't you?\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Initialement, on retient comme crit√®re du r√©sistance (√©tat limite ultime, ELU) le fait que la mati√®re doit rester dans le domaine √©lastique.\n",
            "Actual: Initialement, on retient comme crit√®re de r√©sistance (√©tat limite ultime, ELU) le fait que la mati√®re doit rester dans le domaine √©lastique.\n",
            "Predict: Initialement, on retient comme critique de r√©sistance (√©tat limite ultime, ELU) le fait que la mati√®re doit rester dans le domaine √©lastique.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: La popularit√© de Ptol√©m√©e √©tait en effet all√©e croissante depuis sa accession au tr√¥ne seize ans plus t√¥t.\n",
            "Actual: La popularit√© de Ptol√©m√©e √©tait en effet all√©e croissante depuis son accession au tr√¥ne seize ans plus t√¥t.\n",
            "Predict: La popularit√© de Ptol√©m√©e √©tait en effet croissante depuis son accession au tr√¥ne seize ann√©es plus t√¥t.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: I be out of town for a week or two.\n",
            "Actual: I'll be out of town for a week or two.\n",
            "Predict: I'll be out of town for a week or two.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Este extremo sur estaba 2 m por debajo del nivel de la adllasente Stoa de Zeus.\n",
            "Actual: Este extremo sur estaba 2 m por debajo del nivel de la adyacente Stoa de Zeus.\n",
            "Predict: Este extremo sur se estaba 2 m por debajo del nivel de la adllasente Stoa de Zeus.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: In the movie it were called Footscray station.\n",
            "Actual: In the movie it was called Footscray station.\n",
            "Predict: In the movie it was called Footscray Station.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Cette solutions n'a pas √©t√© r√©utilis√©e √† l'occasions d'autres affaires.\n",
            "Actual: Cette solution n'a pas √©t√© r√©utilis√©e √† l'occasion d'autres affaires.\n",
            "Predict: Cette solution n'a pas √©t√© r√©utilis√©e aux occasions d'autres affaires.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ich weib nicht was jemanden wie ihn zu so etwas treibt Das ist doch total verruckt\n",
            "Actual: Ich wei√ü nicht, was jemanden wie ihn zu so etwas treibt. Das ist doch total verr√ºckt!\n",
            "Predict: Ich wei√ü nicht, was jemanden wie ihn zu so etwas treibt. Das ist doch total verruckt.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: La sym√©trie est facile √† constater ainsi que la courbure apparente relative des trajectoires\n",
            "Actual: La sym√©trie est facile √† constater ainsi que la courbure apparente (relative) des trajectoires.\n",
            "Predict: La sym√©trie est facile √† constater ainsi que la courbure apparente relative des trajectoires.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Recib√≠ unas invitaci√≥n a las fiesta de cumplea√±os.\n",
            "Actual: Recib√≠ una invitaci√≥n a la fiesta de cumplea√±os.\n",
            "Predict: Recib una invitaci√≥n a la fiesta de cumpleaos.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Elle appara√Æt la plus souvent au cours du premier mois de vie et peut √™tre tr√®s rapidement fatale pour la nourrisson.\n",
            "Actual: Elle appara√Æt le plus souvent au cours du premier mois de vie et peut √™tre tr√®s rapidement fatale pour le nourrisson.\n",
            "Predict: Elle appara√Æt le plus souvent au cours du premier mois de vie et peut √™tre tr√®s rapidement fatale pour la nourrisson.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: ¬øNo est√° ya casi hora de comer?\n",
            "Actual: ¬øNo es ya casi hora de comer?\n",
            "Predict: No es ya casi hora de comer?\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Sin embargo, la asiento delantero central es ajustado para una pasajero adulto.\n",
            "Actual: Sin embargo, el asiento delantero central es ajustado para un pasajero adulto.\n",
            "Predict: Sin embargo, el asiento delantero central es ajustado para un pasajero adulto.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Las analizadores elementales modernos tambi√©n son capaces de el determinaci√≥n simult√°nea de azufre junto con CHN en la mismo procedimiento de medici√≥n.\n",
            "Actual: Los analizadores elementales modernos tambi√©n son capaces de la determinaci√≥n simult√°nea de azufre junto con CHN en el mismo procedimiento de medici√≥n.\n",
            "Predict: Los analizadores elementales modernos tambi√©n son capaces de la determinaci√≥n simult√°nea de azufre junto con CHN en el mismo procedimiento de medici√≥n.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ces arguments ont √©t√© √©voqu√©s notamment par la Collectif Libert√© √âgalit√© Justice, qui r√©unit associations (\n",
            "Actual: Ces arguments ont √©t√© √©voqu√©s notamment par le Collectif Libert√© √âgalit√© Justice, qui r√©unit associations (\n",
            "Predict: Ces arguments ont √©t√© √©voqu√©s notamment par le Collectif Libert√© √âgalit√© Justice, qui r√©unit des associations (\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: M√∂gt ihr Tennisse?\n",
            "Actual: M√∂gt ihr Tennis?\n",
            "Predict: M√∂gt ihr Tennis?\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: This caused him to having to feel all the pain he had caused\n",
            "Actual: This caused him to have to feel all the pain he had caused.\n",
            "Predict: This caused him to feel all the pain he had caused.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: D√©j√† √† le 14e si√®cle un hospice y est mentionn√©, dont le si√®ge se trouvait dans le b√¢timent du l‚Äôactuel Mus√©e d‚ÄôHistoire Naturelle.\n",
            "Actual: D√©j√† au 14e si√®cle un hospice y est mentionn√©, dont le si√®ge se trouvait dans le b√¢timent de l‚Äôactuel Mus√©e d‚ÄôHistoire Naturelle.\n",
            "Predict: D√©j√† au 14e si√®cle un hospice y est mentionn√©, dont le si√®ge se trouve dans le b√¢timent de l‚Äôactuel Mus√©e d‚ÄôHistoire Naturelle.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Adolf von Harnack, Einfuhrung, S. 53. Die Kapitel 59‚Äì65 bilden den Schluss.\n",
            "Actual: Adolf von Harnack, Einf√ºhrung, S. 53. Die Kapitel 59‚Äì65 bilden den Schluss.\n",
            "Predict: Adolf von Harnack, Einfuhrung, S. 53. Die Kapitel 59‚Äì65 bilden den Schluss.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Nach seiner Entpflichtungen als Di√∂zesan-Caritasdirektor war er von 1992 bis 1999 Vorsitzender des Caritasverbandese f√ºr die Di√∂zesen Mainz.\n",
            "Actual: Nach seiner Entpflichtung als Di√∂zesan-Caritasdirektor war er von 1992 bis 1999 Vorsitzender des Caritasverbandes f√ºr die Di√∂zese Mainz.\n",
            "Predict: Nach seiner Entpflichtung als Di√∂zesan-Caritasdirektor war er von 1992 bis 1999 Vorsitzender des Caritasverbandes f√ºr die Di√∂zesen Mainz.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: I know exactly how Tom felt.\n",
            "Actual: I know exactly how Tom feels.\n",
            "Predict: I know exactly how Tom felt.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Adem√°s, se han realizaba varios campeonatos de orden de los deportes de habilidad como lo han sido los campeonatos de ajedrez y conocimiento, en los cuales ha exist√≠a amplia participaci√≥n de estudiantes del Liceo.\n",
            "Actual: Adem√°s, se han realizado varios campeonatos de orden de los deportes de habilidad como lo han sido los campeonatos de ajedrez y conocimiento, en los cuales ha existido amplia participaci√≥n de estudiantes del Liceo.\n",
            "Predict: Adem√°s, se han realizado varios campeonatos de orden de los deportes de habilidad como lo han sido los campeonatos de ajedrez y conocimiento.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Rembrandt ahs made a contrast between the rich texture of his robes and his flabby face and fat belly.\n",
            "Actual: Rembrandt has made a contrast between the rich texture of his robes and his flabby face and fat belly.\n",
            "Predict: Rembrandt made a contrast between the rich texture of his robes and his flabby face and fat belly.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Por tanto, lo villas medieval amurallada alcanza su mayor superficie en los citados siglos XIV y XV.\n",
            "Actual: Por tanto, la villa medieval amurallada alcanza su mayor superficie en los citados siglos XIV y XV.\n",
            "Predict: Por tanto, las villas medieval amuralladas alcanza su mayor superficie en los citados siglos XIV y XV.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: I'm not suggest that.\n",
            "Actual: I'm not suggesting that.\n",
            "Predict: I'm not suggesting that.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Tambi√©n seg√∫n esta leyenda, Confucio habr√≠a estaba un enamorado de los p√°jaros, lo que explicar√≠a el nombre de ¬´gorri√≥n¬ª que tambi√©n recibe el juego.\n",
            "Actual: Tambi√©n seg√∫n esta leyenda, Confucio habr√≠a sido un enamorado de los p√°jaros, lo que explicar√≠a el nombre de ¬´gorri√≥n¬ª que tambi√©n recibe el juego.\n",
            "Predict: Tambi√©n segn esta leyenda, Confucio habra estaba un enamorado de los p√°jaros, lo que explicara el nombre de ¬´gorri√≥n¬ª que tambi√©n tambi√©n tambi√©\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: √áiller is Turkeys first and only female prime minister\n",
            "Actual: √áiller is Turkey's first and only female prime minister.\n",
            "Predict: iller is Turkey's first and only female prime minister.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: En casas de escasez de comido, muchos miembras de esta especie se pueden congregar alrededor de una fuente de alimenta, dando la impresi√≥n de que forman una manado.\n",
            "Actual: En casos de escasez de comida, muchos miembros de esta especie se pueden congregar alrededor de una fuente de alimento, dando la impresi√≥n de que forman una manada.\n",
            "Predict: En casas de escasez de comido, muchos miembros de esta especie se pueden congregar alrededor de una fuente de alimenta, dando la impresi√≥n de que for\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Cientos de millones de personas en todo el mundo estan infectadas con gusanos parasitos.\n",
            "Actual: Cientos de millones de personas en todo el mundo est√°n infectadas con gusanos par√°sitos.\n",
            "Predict: Cientos de millones de personas en todo el mundo est√°n infectadas con guanos parasitos.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Si vas sin matr√≠cula te multan\n",
            "Actual: Si vas sin matr√≠cula, te multan.\n",
            "Predict: Si vas sin matrculo, te multan.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: ¬øSoy esperando a que Mary os invite?\n",
            "Actual: ¬øEst√°is esperando a que Mary os invite?\n",
            "Predict: Soy esperando a que Mary os invit√≥?\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ne manquez pas cette exceptionneau occasion.\n",
            "Actual: Ne manquez pas cette exceptionnelle occasion.\n",
            "Predict: Ne manquez pas cette occasion exceptionnelle.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: L'ensemble du la commune √©l√®ves compte.\n",
            "Actual: L'ensemble de la commune compte √©l√®ves.\n",
            "Predict: L'ensemble de la communaut√© √©l√®ves compte.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Des embranchements partaient du centre ville de San Diego et remontaient vers le nord et l'est jusqu'en la Lakeside, avec une ligne s√©par√©e qui faisait le tour de la baie de San Diego pour desservir Coronado Heights, Coronado, et North Island.\n",
            "Actual: Des embranchements partaient du centre ville de San Diego et remontaient vers le nord et l'est jusqu'√† la Lakeside, avec une ligne s√©par√©e qui faisait le tour de la baie de San Diego pour desservir Coronado Heights, Coronado, et North Island.\n",
            "Predict: Des embranchements partaient du centre ville de San Diego et remontaient vers le nord et l'est jusqu'√† la Lakeside, avec une ligne s√©par√©e qui faisait le tour de la baie de San Diego pour desservir Coronado.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Lo bloques de pisos con balcones a menudo son accidentales reflectores de esquina para los sonido y devolver unes eco peculiar para unes observador haciendo unes ruido aguda, como un aplauso, en las proximidades.\n",
            "Actual: Los bloques de pisos con balcones a menudo son accidentales reflectores de esquina para el sonido y devolver un eco peculiar para un observador haciendo un ruido agudo, como un aplauso, en las proximidades.\n",
            "Predict: Los bloques de pisos con balcones a menudo son accidentales reflectores de esquina para el sonido y devolver una eco peculiar para un observador haciendo unas a\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Aunque la catedral pertenece en esencia al g√≥tica radiante, las agujos que rematan los contrafuertes son m√°s propias del g√≥tica flam√≠gero, como tambi√©n lo son las fachados del transepta, de las que hablaremos m√°s tarde.\n",
            "Actual: Aunque la catedral pertenece en esencia al g√≥tico radiante, las agujas que rematan los contrafuertes son m√°s propias del g√≥tico flam√≠gero, como tambi√©n lo son las fachadas del transepto, de las que hablaremos m√°s tarde.\n",
            "Predict: Aunque la catedral pertenece en esencia al g√≥tica radiante, los agujos que rematan los contrafuertes son m√°s propias del g√≥tica flamger.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ensemble, Willem et les jeunes filles vont progressivement comprendre ce que l'famille signifie et ce qui vaut vraiment l'peine d'√™tre prot√©g√© dans leur vie‚Ä¶\n",
            "Actual: Ensemble, Willem et les jeunes filles vont progressivement comprendre ce que la famille signifie et ce qui vaut vraiment la peine d'√™tre prot√©g√© dans leur vie‚Ä¶\n",
            "Predict: Ensemble, Willem et les jeunes filles vont progressivement comprendre ce que la famille signifie et ce qui vaut r√©ellement la peau d'√™tre prot√©g√© dans leur vie...\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Dans ses premi√®res ≈ìuvres elle se concentre sur l'Italie de les Renaissance et √©crit plusieurs romans historiques.\n",
            "Actual: Dans ses premi√®res ≈ìuvres elle se concentre sur l'Italie de la Renaissance et √©crit plusieurs romans historiques.\n",
            "Predict: Dans ses premi√®res uvres, elle se concentre sur l'Italie de la Renaissance et √©crit plusieurs romans historiques.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: It am beautiful, it am fine, it am the noblest form of affection.\n",
            "Actual: It is beautiful, it is fine, it is the noblest form of affection.\n",
            "Predict: It is beautiful, it is fine, it is the noblest form of affection.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Junto con ella Henry, Ed y Hvorst entran para buscar otros cosas aparte de lo medicina, entre ellas uno pistola.\n",
            "Actual: Junto con ella Henry, Ed y Hvorst entran para buscar otras cosas aparte de la medicina, entre ellas una pistola.\n",
            "Predict: Junto con ella Henry, Ed y Hvorst entran para buscar otros cosas aparte de la medicina, entre ellas un pistolo.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Diese Saisone war eine letzte zweigleisige Saison eine Liga und wurde zur n√§chsten Saison dann auch drittklassig.\n",
            "Actual: Diese Saison war die letzte zweigleisige Saison der Liga und wurde zur n√§chsten Saison dann auch drittklassig.\n",
            "Predict: Die Saison war die letzte zweigleisige Saison der Liga und wurde zur n√§chsten Saison dann auch drittklassig.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: I can't tells her now. It's not that simple anymore.\n",
            "Actual: I can't tell her now. It's not that simple anymore.\n",
            "Predict: I can't tell her now. It's not that easy anymore.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Je doit vous parler seul.\n",
            "Actual: Je dois vous parler seul.\n",
            "Predict: Je dois vous parler seul.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: The frog live as tadpole for another 6‚Äì8 month.\n",
            "Actual: The frogs live as tadpoles for another 6‚Äì8 months.\n",
            "Predict: The frog will live as a tadpole for another 6‚Äì8 months.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar:  university has three campuses in Davutpasa, Yƒ±ldƒ±z and Ayazaƒüa.\n",
            "Actual: The university has three campuses in Davutpasa, Yƒ±ldƒ±z and Ayazaƒüa.\n",
            "Predict: The University has three campuses in Davutpasa, Yldz and Ayazaa.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: he wanted to know how everything worked.\n",
            "Actual: He wanted to know how everything worked.\n",
            "Predict: He wanted to know how everything worked.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: En 2008, Telit poursuit sa expansion mondiale via de nouvelles activit√©s r√©gionales, et √©tablit des agences et des usines √† S√£o Paulo au Br√©sil.\n",
            "Actual: En 2008, Telit poursuit son expansion mondiale via de nouvelles activit√©s r√©gionales, et √©tablit des agences et des usines √† S√£o Paulo au Br√©sil.\n",
            "Predict: En 2008, Telit poursuit sa croissance mondiale via de nouvelles activit√©s r√©gionales, et √©tablit des agences et des usines √† So Paulo au Br√©sil.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Saint-Gen√®s-de-Castillon est une communes rurale, car elle fait partie des communes peu ou tr√®s peu denses, au sens de la grilles communale de densit√© de l'\n",
            "Actual: Saint-Gen√®s-de-Castillon est une commune rurale, car elle fait partie des communes peu ou tr√®s peu denses, au sens de la grille communale de densit√© de l'\n",
            "Predict: Saint-Gen√®s-de-Castillon est une commune rurale, car elle fait partie des communes peu ou tr√®s peu denses, au sens de la grille commune de densit√© de l'\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Utilizaron las tecnolog√≠a de Nuwali para mutar a los ombres-simios en varios ombres-bestia para realizar ciertas tareas.\n",
            "Actual: Utilizaron la tecnolog√≠a de Nuwali para mutar a los Hombres-Simios en varios Hombres-Bestia para realizar ciertas tareas.\n",
            "Predict: Utilizaron la tecnologa de Nuwali para mutar a los ombres-simios en varios ombres-bestios para realizar ciertas tareas.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Se desconoce si algunas vez estas canci√≥n fue grabada en unes estudio de grabaci√≥n, pero no ha sido incluida en ningunes disco de audio de Nami, y est√° s√≥lo disponible en las versi√≥n presente aqu√≠.\n",
            "Actual: Se desconoce si alguna vez esta canci√≥n fue grabada en un estudio de grabaci√≥n, pero no ha sido incluida en ning√∫n disco de audio de Nami, y est√° s√≥lo disponible en la versi√≥n presente aqu√≠.\n",
            "Predict: Se desconoce si alguna vez esta canci√≥n fue grabada en un estudio de grabaci√≥n, pero no ha sido incluida en ningun disco de audio de Namib\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Je nai pas besoin daller en fac\n",
            "Actual: Je n'ai pas besoin d'aller en fac.\n",
            "Predict: Je n'ai pas besoin de daller en facette.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Les cheveu de Mary sont naturellement boucl√©s.\n",
            "Actual: Les cheveux de Mary sont naturellement boucl√©s.\n",
            "Predict: Le cheveu de Mary est naturellement boucle.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Por favor, pr√©stame tu cuchilla.\n",
            "Actual: Por favor, pr√©stame tu cuchillo.\n",
            "Predict: Por favor, prestame tu cuchilla.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Ne fais jamais confiance en un √©trangers.\n",
            "Actual: Ne fais jamais confiance √† un √©tranger.\n",
            "Predict: Ne fais jamais confiance en un √©tranger.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Cette travers√©e aura dur√© 34 jours 15 h et 21 min Elle est class√©e au rang des bateaux les plus rapides √† la rame sur loc√©an Atlantique dest en ouest\n",
            "Actual: Cette travers√©e aura dur√© 34 jours, 15 h et 21 min. Elle est class√©e au rang des bateaux les plus rapides √† la rame, sur l'oc√©an Atlantique d'est en ouest.\n",
            "Predict: Cette travers√©e aura dur√© 34 jours 15 h et 21 min Elle est class√©e au rang des bateaux les plus rapides √† la rame sur l'oc√©an Atlantique dest en ouest.\n",
            "------------------------------------------------------------------------------------\n",
            "Input: fix grammar: Scholars such as Gavin Flood, John Keay and Doris Meth Srinivasan having expressed doubts about this suggestion.\n",
            "Actual: Scholars such as Gavin Flood, John Keay and Doris Meth Srinivasan have expressed doubts about this suggestion.\n",
            "Predict: Scholars such as Gavin Flood, John Keay and Doris Meth Srinivasan have expressed doubts about this suggestion.\n",
            "------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tvLe2pzj1g-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}